{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import cPickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_rec(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        obj_struct['pose'] = obj.find('pose').text\n",
    "        obj_struct['truncated'] = int(obj.find('truncated').text)\n",
    "        obj_struct['difficult'] = int(obj.find('difficult').text)\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(bbox.find('xmin').text),\n",
    "                              int(bbox.find('ymin').text),\n",
    "                              int(bbox.find('xmax').text),\n",
    "                              int(bbox.find('ymax').text)]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def voc_ap(rec, prec, use_07_metric=False):\n",
    "    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n",
    "    Compute VOC AP given precision and recall.\n",
    "    If use_07_metric is true, uses the\n",
    "    VOC 07 11 point method (default:False).\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        # correct AP calculation\n",
    "        # first append sentinel values at the end\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "        # compute the precision envelope\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "        # to calculate area under PR curve, look for points\n",
    "        # where X axis (recall) changes value\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        # and sum (\\Delta recall) * prec\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_classnames(classname):\n",
    "    return [line.split(' ')[0][:-1] for line in open(r'E:\\dataset\\Animal\\imagenet\\\\' + classname + '_wnids.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_wnid(imagename):\n",
    "    return imagename[:imagename.rfind('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_image_id(full_id):\n",
    "    ind = full_id.rindex('\\\\')\n",
    "    return full_id[ind+1:-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def voc_eval(detpath,\n",
    "             annopath,\n",
    "             imagesetfile,\n",
    "             classname,\n",
    "             ovthresh=0.5,\n",
    "             use_07_metric=False):\n",
    "    \"\"\"rec, prec, ap = voc_eval(detpath,\n",
    "                                annopath,\n",
    "                                imagesetfile,\n",
    "                                classname,\n",
    "                                [ovthresh],\n",
    "                                [use_07_metric])\n",
    "    Top level function that does the PASCAL VOC evaluation.\n",
    "    detpath: Path to detections\n",
    "        detpath.format(classname) should produce the detection results file.\n",
    "    annopath: Path to annotations\n",
    "        annopath.format(wnid,imagename) should be the xml annotations file.\n",
    "    imagesetfile: Text file containing the list of images, one image per line.\n",
    "    classname: Category name (duh)\n",
    "    cachedir: Directory for caching the annotations\n",
    "    [ovthresh]: Overlap threshold (default = 0.5)\n",
    "    [use_07_metric]: Whether to use VOC07's 11 point AP computation\n",
    "        (default False)\n",
    "    \"\"\"\n",
    "    # assumes detections are in detpath.format(classname)\n",
    "    # assumes annotations are in annopath.format(imagename)\n",
    "    # assumes imagesetfile is a text file with each line an image name\n",
    "    # cachedir caches the annotations in a pickle file\n",
    "\n",
    "    #read classnames in  ImagenetFormat\n",
    "    imagenet_classnames = read_classnames(classname)\n",
    "    \n",
    "    # first load gt\n",
    "\n",
    "    # read list of images\n",
    "    with open(imagesetfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    imagenames = [x.strip() for x in lines]\n",
    "\n",
    "    \n",
    "    # load annots\n",
    "    recs = {}\n",
    "    for i, imagename in enumerate(imagenames):\n",
    "        recs[imagename] = parse_rec(annopath.format(extract_wnid(imagename),imagename))\n",
    "        #if i % 100 == 0:\n",
    "            #print 'Reading annotation for {:d}/{:d}'.format(i + 1, len(imagenames))\n",
    "    # extract gt objects for this class\n",
    "    class_recs = {}\n",
    "    npos = 0\n",
    "    for imagename in imagenames:\n",
    "        R = [obj for obj in recs[imagename] if obj['name'] in imagenet_classnames]\n",
    "        bbox = np.array([x['bbox'] for x in R])\n",
    "        difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
    "        det = [False] * len(R)\n",
    "        npos = npos + sum(~difficult)\n",
    "        class_recs[imagename] = {'bbox': bbox,\n",
    "                                 'difficult': difficult,\n",
    "                                 'det': det}\n",
    "\n",
    "    # read dets\n",
    "    detfile = detpath.format(classname)\n",
    "    with open(detfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    splitlines = [x.strip().split(' ') for x in lines]\n",
    "    image_ids = [extract_image_id(repr(x[0])) for x in splitlines]\n",
    "    confidence = np.array([float(x[1]) for x in splitlines])\n",
    "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
    "\n",
    "    # sort by confidence\n",
    "    sorted_ind = np.argsort(-confidence)\n",
    "    sorted_scores = np.sort(-confidence)\n",
    "    BB = BB[sorted_ind, :]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    nd = len(image_ids)\n",
    "    tp = np.zeros(nd)\n",
    "    fp = np.zeros(nd)\n",
    "    for d in range(nd):\n",
    "        R = class_recs[image_ids[d]]\n",
    "        bb = BB[d, :].astype(float)\n",
    "        ovmax = -np.inf\n",
    "        BBGT = R['bbox'].astype(float)\n",
    "\n",
    "        if BBGT.size > 0:\n",
    "            # compute overlaps\n",
    "            # intersection\n",
    "            ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "            iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "            ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "            iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "            iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "            ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "            inters = iw * ih\n",
    "\n",
    "            # union\n",
    "            uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\n",
    "                   (BBGT[:, 2] - BBGT[:, 0] + 1.) *\n",
    "                   (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "\n",
    "            overlaps = inters / uni\n",
    "            ovmax = np.max(overlaps)\n",
    "            jmax = np.argmax(overlaps)\n",
    "\n",
    "        if ovmax > ovthresh:\n",
    "            if not R['difficult'][jmax]:\n",
    "                if not R['det'][jmax]:\n",
    "                    tp[d] = 1.\n",
    "                    R['det'][jmax] = 1\n",
    "                else:\n",
    "                    fp[d] = 1.\n",
    "        else:\n",
    "            fp[d] = 1.\n",
    "\n",
    "    # compute precision recall\n",
    "    fp = np.cumsum(fp)\n",
    "    tp = np.cumsum(tp)\n",
    "    rec = tp / float(npos)\n",
    "    # avoid divide by zero in case the first detection matches a difficult\n",
    "    # ground truth\n",
    "    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "    ap = voc_ap(rec, prec, use_07_metric)\n",
    "\n",
    "    return rec, prec, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 22] invalid mode ('r') or filename: 'C:\\\\cfnet\\\\data\\\\cfnet-validation\\x0balidation/tc_Kite_ce3/groundtruth.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-40e0903eb2be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\cfnet\\data\\cfnet-validation\\validation/tc_Kite_ce3/groundtruth.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m: [Errno 22] invalid mode ('r') or filename: 'C:\\\\cfnet\\\\data\\\\cfnet-validation\\x0balidation/tc_Kite_ce3/groundtruth.txt'"
     ]
    }
   ],
   "source": [
    "lines = [ line for line in open('C:\\\\cfnet\\data\\cfnet-validation\\validation/tc_Kite_ce3/groundtruth.txt') ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1\n",
      "(4912L,) (4912L,)\n",
      "(14214L,) (14214L,)\n",
      "(20551L,) (20551L,)\n",
      "iter: 2\n",
      "(4963L,) (4963L,)\n",
      "(12034L,) (12034L,)\n",
      "(13991L,) (13991L,)\n",
      "iter: 3\n",
      "(3287L,) (3287L,)\n",
      "(9733L,) (9733L,)\n",
      "(12762L,) (12762L,)\n",
      "iter: 4\n",
      "(2331L,) (2331L,)\n",
      "(10433L,) (10433L,)\n",
      "(10808L,) (10808L,)\n",
      "iter: 5\n",
      "(2139L,) (2139L,)\n",
      "(7615L,) (7615L,)\n",
      "(9813L,) (9813L,)\n",
      "iter: 6\n",
      "(1698L,) (1698L,)\n",
      "(8880L,) (8880L,)\n",
      "(8669L,) (8669L,)\n",
      "iter: 7\n",
      "(2964L,) (2964L,)\n",
      "(8219L,) (8219L,)\n",
      "(7364L,) (7364L,)\n",
      "iter: 8\n",
      "(1695L,) (1695L,)\n",
      "(7202L,) (7202L,)\n",
      "(7113L,) (7113L,)\n",
      "iter: 9\n",
      "(1861L,) (1861L,)\n",
      "(6844L,) (6844L,)\n",
      "(7894L,) (7894L,)\n",
      "iter: 10\n",
      "(2077L,) (2077L,)\n",
      "(6690L,) (6690L,)\n",
      "(7214L,) (7214L,)\n",
      "iter: 11\n",
      "(2256L,) (2256L,)\n",
      "(7633L,) (7633L,)\n",
      "(7158L,) (7158L,)\n",
      "iter: 12\n",
      "(1801L,) (1801L,)\n",
      "(6982L,) (6982L,)\n",
      "(6496L,) (6496L,)\n",
      "iter: 13\n",
      "(1733L,) (1733L,)\n",
      "(8077L,) (8077L,)\n",
      "(7508L,) (7508L,)\n",
      "iter: 14\n",
      "(1565L,) (1565L,)\n",
      "(6947L,) (6947L,)\n",
      "(7364L,) (7364L,)\n",
      "iter: 15\n",
      "(1758L,) (1758L,)\n",
      "(7026L,) (7026L,)\n",
      "(7987L,) (7987L,)\n",
      "iter: 16\n",
      "(1970L,) (1970L,)\n",
      "(6648L,) (6648L,)\n",
      "(6674L,) (6674L,)\n",
      "iter: 17\n",
      "(1935L,) (1935L,)\n",
      "(6036L,) (6036L,)\n",
      "(5893L,) (5893L,)\n",
      "iter: 18\n",
      "(1815L,) (1815L,)\n",
      "(7110L,) (7110L,)\n",
      "(6684L,) (6684L,)\n",
      "iter: 19\n",
      "(1180L,) (1180L,)\n",
      "(5835L,) (5835L,)\n",
      "(6268L,) (6268L,)\n",
      "iter: 20\n",
      "(1315L,) (1315L,)\n",
      "(6671L,) (6671L,)\n",
      "(6140L,) (6140L,)\n",
      "iter: 21\n",
      "(1538L,) (1538L,)\n",
      "(6053L,) (6053L,)\n",
      "(6204L,) (6204L,)\n",
      "iter: 22\n",
      "(1332L,) (1332L,)\n",
      "(6121L,) (6121L,)\n",
      "(7262L,) (7262L,)\n",
      "iter: 23\n",
      "(1362L,) (1362L,)\n",
      "(6287L,) (6287L,)\n",
      "(6148L,) (6148L,)\n",
      "iter: 24\n",
      "(1291L,) (1291L,)\n",
      "(6050L,) (6050L,)\n",
      "(5609L,) (5609L,)\n",
      "iter: 25\n",
      "(1229L,) (1229L,)\n",
      "(5921L,) (5921L,)\n",
      "(6536L,) (6536L,)\n",
      "iter: 26\n",
      "(1823L,) (1823L,)\n",
      "(6048L,) (6048L,)\n",
      "(6869L,) (6869L,)\n",
      "iter: 27\n",
      "(1580L,) (1580L,)\n",
      "(6372L,) (6372L,)\n",
      "(6625L,) (6625L,)\n",
      "iter: 28\n",
      "(1184L,) (1184L,)\n",
      "(5772L,) (5772L,)\n",
      "(7610L,) (7610L,)\n",
      "iter: 29\n",
      "(1345L,) (1345L,)\n",
      "(6824L,) (6824L,)\n",
      "(7532L,) (7532L,)\n",
      "iter: 30\n",
      "(1245L,) (1245L,)\n",
      "(6338L,) (6338L,)\n",
      "(7377L,) (7377L,)\n",
      "iter: 31\n",
      "(1741L,) (1741L,)\n",
      "(5930L,) (5930L,)\n",
      "(7890L,) (7890L,)\n",
      "iter: 32\n",
      "(1417L,) (1417L,)\n",
      "(6429L,) (6429L,)\n",
      "(8269L,) (8269L,)\n",
      "iter: 33\n",
      "(1437L,) (1437L,)\n",
      "(5868L,) (5868L,)\n",
      "(7738L,) (7738L,)\n",
      "iter: 34\n",
      "(1135L,) (1135L,)\n",
      "(5671L,) (5671L,)\n",
      "(7969L,) (7969L,)\n",
      "iter: 35\n",
      "(1367L,) (1367L,)\n",
      "(5228L,) (5228L,)\n",
      "(6679L,) (6679L,)\n",
      "iter: 36\n",
      "(1211L,) (1211L,)\n",
      "(5710L,) (5710L,)\n",
      "(6842L,) (6842L,)\n",
      "iter: 37\n",
      "(1205L,) (1205L,)\n",
      "(5652L,) (5652L,)\n",
      "(7515L,) (7515L,)\n",
      "iter: 38\n",
      "(1644L,) (1644L,)\n",
      "(6036L,) (6036L,)\n",
      "(7142L,) (7142L,)\n",
      "iter: 39\n",
      "(1632L,) (1632L,)\n",
      "(6168L,) (6168L,)\n",
      "(7524L,) (7524L,)\n",
      "iter: 40\n",
      "(1099L,) (1099L,)\n",
      "(5227L,) (5227L,)\n",
      "(6652L,) (6652L,)\n",
      "iter: 41\n",
      "(1130L,) (1130L,)\n",
      "(6025L,) (6025L,)\n",
      "(7032L,) (7032L,)\n",
      "iter: 42\n",
      "(1010L,) (1010L,)\n",
      "(5731L,) (5731L,)\n",
      "(8087L,) (8087L,)\n",
      "iter: 43\n",
      "(1398L,) (1398L,)\n",
      "(6343L,) (6343L,)\n",
      "(8403L,) (8403L,)\n",
      "iter: 44\n",
      "(1150L,) (1150L,)\n",
      "(6156L,) (6156L,)\n",
      "(6510L,) (6510L,)\n",
      "iter: 45\n",
      "(1238L,) (1238L,)\n",
      "(6534L,) (6534L,)\n",
      "(7532L,) (7532L,)\n",
      "iter: 46\n",
      "(1327L,) (1327L,)\n",
      "(6696L,) (6696L,)\n",
      "(6612L,) (6612L,)\n",
      "iter: 47\n",
      "(1588L,) (1588L,)\n",
      "(6043L,) (6043L,)\n",
      "(7320L,) (7320L,)\n",
      "iter: 48\n",
      "(1467L,) (1467L,)\n",
      "(6279L,) (6279L,)\n",
      "(6838L,) (6838L,)\n",
      "iter: 49\n",
      "(1638L,) (1638L,)\n",
      "(7155L,) (7155L,)\n",
      "(8826L,) (8826L,)\n",
      "iter: 50\n",
      "(1296L,) (1296L,)\n",
      "(5158L,) (5158L,)\n",
      "(7590L,) (7590L,)\n",
      "iter: 51\n",
      "(1172L,) (1172L,)\n",
      "(5713L,) (5713L,)\n",
      "(6925L,) (6925L,)\n",
      "iter: 52\n",
      "(929L,) (929L,)\n",
      "(6360L,) (6360L,)\n",
      "(6154L,) (6154L,)\n",
      "iter: 53\n",
      "(1302L,) (1302L,)\n",
      "(6260L,) (6260L,)\n",
      "(7878L,) (7878L,)\n",
      "iter: 54\n",
      "(1050L,) (1050L,)\n",
      "(5890L,) (5890L,)\n",
      "(8103L,) (8103L,)\n",
      "iter: 55\n",
      "(983L,) (983L,)\n",
      "(5164L,) (5164L,)\n",
      "(6373L,) (6373L,)\n",
      "iter: 56\n",
      "(1177L,) (1177L,)\n",
      "(5536L,) (5536L,)\n",
      "(7785L,) (7785L,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot  as plt\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "  \n",
    "\n",
    "classnames = ['person','animal','bird']\n",
    "results = {}\n",
    "mAPs = []\n",
    "for iteration in range(1,57):\n",
    "    print 'iter: {}'.format(iteration)\n",
    "    for classname in classnames:\n",
    "        results[classname] = voc_eval(r'C:\\darknet\\build\\darknet\\x64\\results\\comp4_det_test_{0}-animal-' + str(iteration) + '000.txt',\n",
    "                r'E:\\dataset\\Animal\\imagenet\\synsets\\{0}\\annotations\\{1}.xml',\n",
    "                r'E:\\dataset\\Animal\\imagenet\\imagesetfile_dev_val.txt',\n",
    "                classname)\n",
    "    mAP = 0\n",
    "    fig= plt.figure()\n",
    "    for i,classname in enumerate(classnames):\n",
    "        rec,prec,ap = results[classname]\n",
    "        print rec.shape,prec.shape\n",
    "        mAP+=ap\n",
    "        ax = fig.add_subplot(221+i)  \n",
    "        plt.title(classname)\n",
    "        plt.plot(rec,label='recall')\n",
    "        plt.plot(prec,label='precision')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        fig.subplots_adjust(hspace=.5)\n",
    "        mAP = mAP/len(classnames)\n",
    "    mAPs.append(mAP)\n",
    "\n",
    "    ax = fig.add_subplot(224)\n",
    "    plt.title('mAP')\n",
    "    ax.bar(1,mAP,0.05)\n",
    "\n",
    "    ax.set_yticks(np.linspace(0,1,11))\n",
    "    #ax.set_yticks(np.linspace(0,1,11))\n",
    "    savefig(r'C:\\darknet\\build\\darknet\\x64\\eval\\animal\\animal_evaluation_notick_{}.jpg'.format(iteration),dpi=200)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= plt.figure()\n",
    "plt.plot(mAPs)\n",
    "plt.ylabel('mean Average Precision')\n",
    "plt.xlabel('number of iterations in 1000s')\n",
    "plt.yticks(np.linspace(0,0.5,11))\n",
    "plt.grid()\n",
    "savefig(r'C:\\darknet\\build\\darknet\\x64\\eval\\animal\\evaluation.png',dpi=200)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "print len(old_mAPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
