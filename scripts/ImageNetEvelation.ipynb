{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_rec(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        obj_struct['pose'] = obj.find('pose').text\n",
    "        obj_struct['truncated'] = int(obj.find('truncated').text)\n",
    "        obj_struct['difficult'] = int(obj.find('difficult').text)\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(bbox.find('xmin').text),\n",
    "                              int(bbox.find('ymin').text),\n",
    "                              int(bbox.find('xmax').text),\n",
    "                              int(bbox.find('ymax').text)]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def voc_ap(rec, prec, use_07_metric=False):\n",
    "    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n",
    "    Compute VOC AP given precision and recall.\n",
    "    If use_07_metric is true, uses the\n",
    "    VOC 07 11 point method (default:False).\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        # correct AP calculation\n",
    "        # first append sentinel values at the end\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "        # compute the precision envelope\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "        # to calculate area under PR curve, look for points\n",
    "        # where X axis (recall) changes value\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        # and sum (\\Delta recall) * prec\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_classnames(classname):\n",
    "    return [line.split(' ')[0][:-1] for line in open(r'E:\\dataset\\Animal\\imagenet\\\\' + classname + '_wnids.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_wnid(imagename):\n",
    "    return imagename[:imagename.rfind('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_image_id(full_id):\n",
    "    ind = full_id.rindex('\\\\')\n",
    "    return full_id[ind+1:-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def voc_eval(detpath,\n",
    "             annopath,\n",
    "             imagesetfile,\n",
    "             classname,\n",
    "             ovthresh=0.5,\n",
    "             use_07_metric=False):\n",
    "    \"\"\"rec, prec, ap = voc_eval(detpath,\n",
    "                                annopath,\n",
    "                                imagesetfile,\n",
    "                                classname,\n",
    "                                [ovthresh],\n",
    "                                [use_07_metric])\n",
    "    Top level function that does the PASCAL VOC evaluation.\n",
    "    detpath: Path to detections\n",
    "        detpath.format(classname) should produce the detection results file.\n",
    "    annopath: Path to annotations\n",
    "        annopath.format(wnid,imagename) should be the xml annotations file.\n",
    "    imagesetfile: Text file containing the list of images, one image per line.\n",
    "    classname: Category name (duh)\n",
    "    cachedir: Directory for caching the annotations\n",
    "    [ovthresh]: Overlap threshold (default = 0.5)\n",
    "    [use_07_metric]: Whether to use VOC07's 11 point AP computation\n",
    "        (default False)\n",
    "    \"\"\"\n",
    "    # assumes detections are in detpath.format(classname)\n",
    "    # assumes annotations are in annopath.format(imagename)\n",
    "    # assumes imagesetfile is a text file with each line an image name\n",
    "    # cachedir caches the annotations in a pickle file\n",
    "\n",
    "    #read classnames in  ImagenetFormat\n",
    "    imagenet_classnames = read_classnames(classname)\n",
    "    \n",
    "    # first load gt\n",
    "\n",
    "    # read list of images\n",
    "    with open(imagesetfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    imagenames = [x.strip() for x in lines]\n",
    "\n",
    "    \n",
    "    # load annots\n",
    "    recs = {}\n",
    "    for i, imagename in enumerate(imagenames):\n",
    "        recs[imagename] = parse_rec(annopath.format(extract_wnid(imagename),imagename))\n",
    "        #if i % 100 == 0:\n",
    "            #print 'Reading annotation for {:d}/{:d}'.format(i + 1, len(imagenames))\n",
    "    # extract gt objects for this class\n",
    "    class_recs = {}\n",
    "    npos = 0\n",
    "    for imagename in imagenames:\n",
    "        R = [obj for obj in recs[imagename] if obj['name'] in imagenet_classnames]\n",
    "        bbox = np.array([x['bbox'] for x in R])\n",
    "        difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
    "        det = [False] * len(R)\n",
    "        npos = npos + sum(~difficult)\n",
    "        class_recs[imagename] = {'bbox': bbox,\n",
    "                                 'difficult': difficult,\n",
    "                                 'det': det}\n",
    "\n",
    "    # read dets\n",
    "    detfile = detpath.format(classname)\n",
    "    with open(detfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    if len(lines)<=0:\n",
    "        return None,None,None\n",
    "    \n",
    "    splitlines = [x.strip().split(' ') for x in lines]\n",
    "    image_ids = [extract_image_id(repr(x[0])) for x in splitlines]\n",
    "    confidence = np.array([float(x[1]) for x in splitlines])\n",
    "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
    "\n",
    "    # sort by confidence\n",
    "    sorted_ind = np.argsort(-confidence)\n",
    "    sorted_scores = np.sort(-confidence)\n",
    "    BB = BB[sorted_ind, :]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    nd = len(image_ids)\n",
    "    tp = np.zeros(nd)\n",
    "    fp = np.zeros(nd)\n",
    "    for d in range(nd):\n",
    "        R = class_recs[image_ids[d]]\n",
    "        bb = BB[d, :].astype(float)\n",
    "        ovmax = -np.inf\n",
    "        BBGT = R['bbox'].astype(float)\n",
    "\n",
    "        if BBGT.size > 0:\n",
    "            # compute overlaps\n",
    "            # intersection\n",
    "            ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "            iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "            ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "            iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "            iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
    "            ih = np.maximum(iymax - iymin + 1., 0.)\n",
    "            inters = iw * ih\n",
    "\n",
    "            # union\n",
    "            uni = ((bb[2] - bb[0] + 1.) * (bb[3] - bb[1] + 1.) +\n",
    "                   (BBGT[:, 2] - BBGT[:, 0] + 1.) *\n",
    "                   (BBGT[:, 3] - BBGT[:, 1] + 1.) - inters)\n",
    "\n",
    "            overlaps = inters / uni\n",
    "            ovmax = np.max(overlaps)\n",
    "            jmax = np.argmax(overlaps)\n",
    "\n",
    "        if ovmax > ovthresh:\n",
    "            if not R['difficult'][jmax]:\n",
    "                if not R['det'][jmax]:\n",
    "                    tp[d] = 1.\n",
    "                    R['det'][jmax] = 1\n",
    "                else:\n",
    "                    fp[d] = 1.\n",
    "        else:\n",
    "            fp[d] = 1.\n",
    "\n",
    "    # compute precision recall\n",
    "    fp = np.cumsum(fp)\n",
    "    tp = np.cumsum(tp)\n",
    "    rec = tp / float(npos)\n",
    "    # avoid divide by zero in case the first detection matches a difficult\n",
    "    # ground truth\n",
    "    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "    ap = voc_ap(rec, prec, use_07_metric)\n",
    "    \n",
    "    return rec, prec, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5945,) (5945,)\n",
      "(9849,) (9849,)\n",
      "iter: 2\n",
      "(63309,) (63309,)\n",
      "(85913,) (85913,)\n",
      "iter: 3\n",
      "(47117,) (47117,)\n",
      "(64590,) (64590,)\n",
      "iter: 4\n",
      "(37163,) (37163,)\n",
      "(57407,) (57407,)\n",
      "iter: 5\n",
      "(36477,) (36477,)\n",
      "(57631,) (57631,)\n",
      "iter: 6\n",
      "(28890,) (28890,)\n",
      "(50130,) (50130,)\n",
      "iter: 7\n",
      "(28187,) (28187,)\n",
      "(45073,) (45073,)\n",
      "iter: 8\n",
      "(26051,) (26051,)\n",
      "(39960,) (39960,)\n",
      "iter: 9\n",
      "(23015,) (23015,)\n",
      "(43610,) (43610,)\n",
      "iter: 10\n",
      "(22056,) (22056,)\n",
      "(42932,) (42932,)\n",
      "iter: 11\n",
      "(22709,) (22709,)\n",
      "(35765,) (35765,)\n",
      "iter: 12\n",
      "(21125,) (21125,)\n",
      "(41539,) (41539,)\n",
      "iter: 13\n",
      "(21255,) (21255,)\n",
      "(33782,) (33782,)\n",
      "iter: 14\n",
      "(19151,) (19151,)\n",
      "(36691,) (36691,)\n",
      "iter: 15\n",
      "(19294,) (19294,)\n",
      "(31537,) (31537,)\n",
      "iter: 16\n",
      "(18244,) (18244,)\n",
      "(35442,) (35442,)\n",
      "iter: 17\n",
      "(17510,) (17510,)\n",
      "(30508,) (30508,)\n",
      "iter: 18\n",
      "(15557,) (15557,)\n",
      "(36129,) (36129,)\n",
      "iter: 19\n",
      "(17273,) (17273,)\n",
      "(31554,) (31554,)\n",
      "iter: 20\n",
      "(17684,) (17684,)\n",
      "(32428,) (32428,)\n",
      "iter: 21\n",
      "(19919,) (19919,)\n",
      "(36240,) (36240,)\n",
      "iter: 22\n",
      "(16382,) (16382,)\n",
      "(29416,) (29416,)\n",
      "iter: 23\n",
      "(14638,) (14638,)\n",
      "(29872,) (29872,)\n",
      "iter: 24\n",
      "(16223,) (16223,)\n",
      "(28744,) (28744,)\n",
      "iter: 25\n",
      "(16656,) (16656,)\n",
      "(24505,) (24505,)\n",
      "iter: 26\n",
      "(15499,) (15499,)\n",
      "(24417,) (24417,)\n",
      "iter: 27\n",
      "(15320,) (15320,)\n",
      "(24016,) (24016,)\n",
      "iter: 28\n",
      "(15609,) (15609,)\n",
      "(23809,) (23809,)\n",
      "iter: 29\n",
      "(15966,) (15966,)\n",
      "(24226,) (24226,)\n",
      "iter: 30\n",
      "(14607,) (14607,)\n",
      "(26663,) (26663,)\n",
      "iter: 31\n",
      "(15447,) (15447,)\n",
      "(24641,) (24641,)\n",
      "iter: 32\n",
      "(13903,) (13903,)\n",
      "(26720,) (26720,)\n",
      "iter: 33\n",
      "(14508,) (14508,)\n",
      "(26906,) (26906,)\n",
      "iter: 34\n",
      "(13249,) (13249,)\n",
      "(22421,) (22421,)\n",
      "iter: 35\n",
      "(14661,) (14661,)\n",
      "(25149,) (25149,)\n",
      "iter: 36\n",
      "(13332,) (13332,)\n",
      "(21579,) (21579,)\n",
      "iter: 37\n",
      "(13088,) (13088,)\n",
      "(23980,) (23980,)\n",
      "iter: 38\n",
      "(12883,) (12883,)\n",
      "(24035,) (24035,)\n",
      "iter: 39\n",
      "(12577,) (12577,)\n",
      "(22593,) (22593,)\n",
      "iter: 40\n",
      "(12752,) (12752,)\n",
      "(20725,) (20725,)\n",
      "iter: 41\n",
      "(13692,) (13692,)\n",
      "(23225,) (23225,)\n",
      "iter: 42\n",
      "(14955,) (14955,)\n",
      "(20953,) (20953,)\n",
      "iter: 43\n",
      "(13160,) (13160,)\n",
      "(19365,) (19365,)\n",
      "iter: 44\n",
      "(13371,) (13371,)\n",
      "(21443,) (21443,)\n",
      "iter: 45\n",
      "(12477,) (12477,)\n",
      "(18848,) (18848,)\n",
      "iter: 46\n",
      "(12345,) (12345,)\n",
      "(21396,) (21396,)\n",
      "iter: 47\n",
      "(11856,) (11856,)\n",
      "(20691,) (20691,)\n",
      "iter: 48\n",
      "(12314,) (12314,)\n",
      "(20380,) (20380,)\n",
      "iter: 49\n",
      "(11615,) (11615,)\n",
      "(20430,) (20430,)\n",
      "iter: 50\n",
      "(11866,) (11866,)\n",
      "(21422,) (21422,)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot  as plt\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "from collections import defaultdict  \n",
    "\n",
    "classnames = ['person', 'animal']\n",
    "results = {}\n",
    "mAPs = defaultdict(list)\n",
    "for iteration in range(1,51):\n",
    "    print ('iter: {}'.format(iteration))\n",
    "    for classname in classnames:\n",
    "        results[classname] = voc_eval(r'C:\\darknet\\build\\darknet\\x64\\results\\comp4_det_test_{0}-animal17-' + str(iteration) + '000.txt',\n",
    "                r'E:\\dataset\\Animal\\imagenet\\synsets\\{0}\\annotations\\{1}.xml',\n",
    "                r'E:\\dataset\\Animal\\imagenet\\imagesetfile_dev_val.txt',\n",
    "                classname,use_07_metric=True)\n",
    "    mAP = 0\n",
    "    fig= plt.figure()\n",
    "    count = 0\n",
    "    \n",
    "    for i,classname in enumerate(classnames):\n",
    "        rec,prec,ap = results[classname]\n",
    "        if rec is None:\n",
    "            continue\n",
    "        print (rec.shape,prec.shape)\n",
    "        mAP+=ap\n",
    "        ax = fig.add_subplot(221+i)  \n",
    "        plt.title(classname)\n",
    "        plt.plot(rec,label='recall')\n",
    "        plt.plot(prec,label='precision')\n",
    "        F1 = 2*(prec*rec)/(prec+rec)\n",
    "        plt.plot(F1,label='F1 score')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        fig.subplots_adjust(hspace=.5)\n",
    "        \n",
    "        mAPs[classname].append(ap)\n",
    "    mAP = mAP/len(classnames)\n",
    "    ax = fig.add_subplot(224)\n",
    "    plt.title('mAP')\n",
    "    ax.bar(1,mAP,0.05)\n",
    "    ax.text(1,0.6,'%.2f'%(mAP),color='red')\n",
    "    ax.set_yticks(np.linspace(0,1,11))\n",
    "    #ax.set_yticks(np.linspace(0,1,11))\n",
    "    savefig(r'C:\\darknet\\build\\darknet\\x64\\eval\\animal17\\animal17_evaluation_{}.jpg'.format(iteration),dpi=200)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "for cls in classnames: \n",
    "    fig= plt.figure()\n",
    "    plt.plot(mAPs[cls])\n",
    "    plt.ylabel('mean Average Precision')\n",
    "    plt.xlabel('number of iterations in 1000s')\n",
    "    plt.yticks(np.linspace(0,1,11))\n",
    "    plt.grid()\n",
    "    savefig(r'C:\\darknet\\build\\darknet\\x64\\eval\\animal17\\evaluation_{}.png'.format(cls),dpi=200)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
